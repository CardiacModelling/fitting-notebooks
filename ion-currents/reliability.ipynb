{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking your fitting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking your optimisation set-up with synthetic data studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking your real-data results with repeated fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sing the boundaries-with-sampling object defined above, we can run fitting experiments repeatedly, from different starting points:\n",
    "\n",
    "1. Sample $x_0[i]$ from within the boundaries.\n",
    "2. Run the i-th optimisation, starting from $x_0[i]$.\n",
    "3. Store the resulting lowest error $f_\\text{opt}[i]$ and best position $x_\\text{opt}[i]$.\n",
    "\n",
    "When working with real data, where the \"true\" solution is unknown, repeated fits are crucial to test the reliability of the obtained results.\n",
    "\n",
    "We recommend the following strategy:\n",
    "\n",
    "1. Run at least 50 repeats, and plot the results from each in a boundary plot as shown above.\n",
    "2. Identify the repeat $i_\\text{best}$ with the lowest error $f_\\text{opt}[i_\\text{best}]$\n",
    "3. Define some distance measure, e.g. euclidean distance in a space with log-transformed alpha parameters, and calculate the distance $d(x_\\text{opt}[i], x_\\text{opt}[i_\\text{best}])$ for each of the 50 repeats\n",
    "\n",
    "For a succesful optimisation, this should result in a distribution where a large proportion of the distances (e.g. 80\\%) are close to 0.\n",
    "A very low number of distances near zero (e.g. less than 5) can indicate that the \"best\" result was very difficult to find, but could also show that the best result found was not a global optimum.\n",
    "If this occurs, either the optimisation needs to be improved somehow, or the number of repeats should be increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the usefulness of your model: training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we\n",
    "\n",
    "In the next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
